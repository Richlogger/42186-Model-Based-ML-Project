{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.optim import Adam\n",
    "from pyro.nn import PyroModule, PyroSample\n",
    "from pyro.infer.autoguide import AutoDiagonalNormal\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed\n",
    "pyro.set_rng_seed(42)\n",
    "\n",
    "# File paths\n",
    "train_path = \"/work3/s214806/working_chunk_train.csv\"\n",
    "val_path = \"/work3/s214806/working_chunk_val.csv\"\n",
    "test_path = \"/work3/s214806/working_chunk_test.csv\"\n",
    "\n",
    "LABEL_MAPPING = {'AML': 0, 'ALL': 1, 'Normal': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess data\n",
    "def load_and_preprocess(path):\n",
    "    df = pd.read_csv(path, index_col=0, low_memory=False).T\n",
    "    print(f\"Gene expression data BEFORE removing non-numeric columns: {df.shape[1]}\")\n",
    "\n",
    "    labels = df['Cancer'].map(LABEL_MAPPING).dropna()\n",
    "\n",
    "    gene_expressions = df.drop(['Cancer', 'Preservation Method', 'Tissue Type', 'Tumor Descriptor', 'Specimen Type'], \n",
    "                               axis=1, errors='ignore')\n",
    "\n",
    "    gene_expressions = gene_expressions.apply(pd.to_numeric, errors='coerce')\n",
    "    gene_expressions = gene_expressions.dropna(axis=1)\n",
    "    print(f\"Gene expression data AFTER removing non-numeric columns: {gene_expressions.shape[1]}\")\n",
    "\n",
    "    gene_expressions = gene_expressions.astype(np.float32)\n",
    "    return gene_expressions.values, labels.loc[gene_expressions.index].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "# x_train_np, y_train_np = load_and_preprocess(train_path)\n",
    "x_val_np, y_val_np = load_and_preprocess(val_path)\n",
    "\n",
    "# # Standardize input features\n",
    "# x_train_mean = x_train_np.mean(axis=1)\n",
    "# x_train_std = x_train_np.std(axis=1)\n",
    "# x_train_np = (x_train_np - x_train_mean) / x_train_std\n",
    "\n",
    "x_val_mean = x_val_np.mean(axis=0)\n",
    "x_val_std = x_val_np.std(axis=0)\n",
    "x_val_np = (x_val_np - x_val_mean) / x_val_std\n",
    "\n",
    "\n",
    "# # Convert to tensors\n",
    "# x_train = torch.tensor(x_train_np, dtype=torch.float32)\n",
    "# y_train = torch.tensor(y_train_np, dtype=torch.long)\n",
    "\n",
    "x_val = torch.tensor(x_val_np, dtype=torch.float32)\n",
    "y_val = torch.tensor(y_val_np, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"x_train shape: \", x_train.shape)\n",
    "# print(f\"y_train shape: \", y_train.shape)\n",
    "\n",
    "print(f\"x_val shape: \", x_val.shape)\n",
    "print(f\"y_val shape: \", y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class HDPMMClassifier(PyroModule):\n",
    "#     def __init__(self, num_genes, num_classes=3, num_clusters=20):\n",
    "#         super().__init__()\n",
    "#         self.K = num_clusters\n",
    "#         self.num_genes = num_genes\n",
    "#         self.num_classes = num_classes\n",
    "\n",
    "#         # Using lambdas to return a distribution\n",
    "#         self.cluster_means = PyroSample(\n",
    "#             lambda self: dist.Normal(0., 1.).expand([self.K, self.num_genes]).to_event(2)\n",
    "#         )\n",
    "#         self.cluster_scales = PyroSample(\n",
    "#             lambda self: dist.HalfCauchy(1.0).expand([self.K, self.num_genes]).to_event(2)\n",
    "#         )\n",
    "#         self.classifier_weights = PyroSample(\n",
    "#             lambda self: dist.Normal(0., 1.).expand([self.num_classes, self.K]).to_event(2)\n",
    "#         )\n",
    "\n",
    "#         self.alpha = 1.0  # Concentration parameter for stick-breaking\n",
    "\n",
    "#     def model(self, x, y=None):\n",
    "#         N = x.shape[0]\n",
    "\n",
    "#         cluster_means = pyro.sample(\"cluster_means\", self.cluster_means)\n",
    "#         cluster_scales = pyro.sample(\"cluster_scales\", self.cluster_scales)\n",
    "#         classifier_weights = pyro.sample(\"classifier_weights\", self.classifier_weights)\n",
    "\n",
    "#         beta = pyro.sample(\"beta\", dist.Beta(1, self.alpha).expand([self.K - 1]))\n",
    "#         weights = self.stick_breaking(beta)  # shape: [K]\n",
    "\n",
    "#         with pyro.plate(\"samples\", N):\n",
    "#             z = pyro.sample(\"z\", dist.Categorical(probs=weights.expand([N, self.K])))\n",
    "#             mu = cluster_means[z]\n",
    "#             sigma = cluster_scales[z]\n",
    "\n",
    "#             pyro.sample(\"obs\", dist.Normal(mu, sigma).to_event(1), obs=x)\n",
    "\n",
    "#             z_onehot = F.one_hot(z, num_classes=self.K).float()\n",
    "#             logits = torch.matmul(z_onehot, classifier_weights.T)\n",
    "\n",
    "#             pyro.sample(\"label\", dist.Categorical(logits=logits), obs=y)\n",
    "\n",
    "#     def guide(self, x, y=None):\n",
    "#         # Variational distributions over global parameters\n",
    "#         cluster_means_loc = pyro.param(\"cluster_means_loc\", torch.randn(self.K, self.num_genes))\n",
    "#         cluster_means_scale = pyro.param(\"cluster_means_scale\", torch.ones(self.K, self.num_genes), constraint=dist.constraints.positive)\n",
    "\n",
    "#         cluster_scales_loc = pyro.param(\"cluster_scales_loc\", torch.ones(self.K, self.num_genes), constraint=dist.constraints.positive)\n",
    "\n",
    "#         classifier_weights_loc = pyro.param(\"classifier_weights_loc\", torch.randn(self.num_classes, self.K))\n",
    "#         classifier_weights_scale = pyro.param(\"classifier_weights_scale\", torch.ones(self.num_classes, self.K), constraint=dist.constraints.positive)\n",
    "\n",
    "#         beta_conc1 = pyro.param(\"beta_conc1\", torch.ones(self.K - 1), constraint=dist.constraints.positive)\n",
    "#         beta_conc0 = pyro.param(\"beta_conc0\", torch.ones(self.K - 1), constraint=dist.constraints.positive)\n",
    "\n",
    "#         pyro.sample(\"cluster_means\", dist.Normal(cluster_means_loc, cluster_means_scale).to_event(2))\n",
    "#         pyro.sample(\"cluster_scales\", dist.HalfCauchy(cluster_scales_loc).to_event(2))\n",
    "#         pyro.sample(\"classifier_weights\", dist.Normal(classifier_weights_loc, classifier_weights_scale).to_event(2))\n",
    "#         pyro.sample(\"beta\", dist.Beta(beta_conc1, beta_conc0))\n",
    "\n",
    "#     def stick_breaking(self, beta):\n",
    "#         remaining_stick = torch.cumprod(1 - beta, dim=-1)\n",
    "#         remaining_stick = torch.cat([torch.tensor([1.0], device=beta.device), remaining_stick], dim=0)\n",
    "#         weights = beta * remaining_stick[:-1]\n",
    "#         final_cluster = 1 - weights.sum(dim=-1, keepdim=True)\n",
    "#         weights = torch.cat([weights, final_cluster], dim=-1)\n",
    "#         return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize model\n",
    "# hdpmm_model = HDPMMClassifier(num_genes=x_train.shape[1])\n",
    "# guide = AutoDiagonalNormal(hdpmm_model.model)\n",
    "# svi = SVI(hdpmm_model.model, guide, Adam({\"lr\": 1e-2}), loss=Trace_ELBO())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Training loop\n",
    "# num_steps = 500\n",
    "# for step in tqdm(range(num_steps)):\n",
    "#     loss = svi.step(x_train, y_train)\n",
    "#     if step % 50 == 0:\n",
    "#         print(f\"Step {step} - Loss: {loss:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "course_42186",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
